{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import the required libraries:\n",
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intializing the new tokenizer + model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute this script to set values for different parameters:\n",
    "BATCH_SIZE = 40\n",
    "EPOCHS = 20\n",
    "LSTM_NODES = 256\n",
    "NUM_SENTENCES = 20000\n",
    "MAX_SENTENCE_LENGTH = 50\n",
    "VOCAB_SIZE = 10000\n",
    "# 4096 is the dimension returned from the tok_embeddings.weight key of the pretrained aix model\n",
    "EMBEDDING_SIZE = 4096\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('tokenizer.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the target sequences ready to be passed into the model features will be the tokenized sequences, labels will be the binary classification of which set of tokens represents the bad sequence. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length: 98\n",
      "Train Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
      "Test Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.orm import  sessionmaker\n",
    "from Juliet2_Schema import Cases, engine, VLW\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Query the database and get a list of Cases objects for each CWE\n",
    "records = session.query(VLW).all()\n",
    "\n",
    "data = [record.vlw_content for record in records]\n",
    "labels  = [record.vulnerability_location  for record in records]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "# Encode sentences \n",
    "train_sequences = [[sp.EncodeAsIds(line) for line in text.split('\\n')[:40]] for text in train_data]\n",
    "test_sequences = [[sp.EncodeAsIds(line) for line in text.split('\\n')[:40]] for text in test_data]\n",
    "\n",
    "\n",
    "# This version could be useful if I want to avoid the padding issue later on. \n",
    "# train_sequences = [[sp.EncodeAsIds(line) for line in text.split('\\n')[:40]] for text in train_data if len(text.split('\\n')) >= 40]\n",
    "# test_sequences = [[sp.EncodeAsIds(line) for line in text.split('\\n')[:40]] for text in test_data if len(text.split('\\n')) >= 40]\n",
    "\n",
    "# # Print the number of train and test sequences\n",
    "# print(f\"Number of train sequences: {len(train_sequences)}\")\n",
    "# print(f\"Number of test sequences: {len(test_sequences)}\")\n",
    "\n",
    "\n",
    "# Finding the longest indivudial tokenized sentences\n",
    "max_length_train = max(max(len(seq) for seq in text) for text in train_sequences)\n",
    "max_length_test = max(max(len(seq) for seq in text) for text in test_sequences)\n",
    "\n",
    "# Get the maximum length across both sets\n",
    "max_length = max(max_length_train, max_length_test)\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "\n",
    "num_classes = 40  \n",
    "train_labels = torch.stack([torch.nn.functional.one_hot(torch.tensor(label), num_classes=num_classes) for label in train_labels])\n",
    "test_labels = torch.stack([torch.nn.functional.one_hot(torch.tensor(label), num_classes=num_classes) for label in test_labels])\n",
    "\n",
    "print('max_length:', max_length)\n",
    "print('Train Labels:', train_labels[0])\n",
    "print('Test Labels:', test_labels[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding + Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequences shape: (40, 98)\n",
      "Test sequences shape: (40, 98)\n"
     ]
    }
   ],
   "source": [
    "# Pad each individual sequence to a length of 98\n",
    "train_sequences_padded = [pad_sequences(text, maxlen=98, padding='post') for text in train_sequences]\n",
    "test_sequences_padded = [pad_sequences(text, maxlen=98, padding='post') for text in test_sequences]\n",
    "\n",
    "print('Train sequences shape:', train_sequences_padded[0].shape)\n",
    "print('Test sequences shape:', test_sequences_padded[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging the shape here there is a 39 dimension tensor throwing things off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining train sequences: 43369\n",
      "Number of remaining train labels: 43369\n"
     ]
    }
   ],
   "source": [
    "# Create a list of indices where the sequence length is not 40\n",
    "drop_indices = [i for i, seq in enumerate(train_sequences_padded) if len(seq) != 40]\n",
    "\n",
    "# Drop these indices from train_sequences_padded and train_labels\n",
    "train_sequences_padded = [seq for i, seq in enumerate(train_sequences_padded) if i not in drop_indices]\n",
    "train_labels = [label for i, label in enumerate(train_labels) if i not in drop_indices]\n",
    "\n",
    "# Print the number of remaining sequences and labels\n",
    "print(f\"Number of remaining train sequences: {len(train_sequences_padded)}\")\n",
    "print(f\"Number of remaining train labels: {len(train_labels)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just going to cull the few thousand or so that had an inoccrect length, still testing about 40k windows it looks like. Reapeating the same for testing group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining test sequences: 10816\n",
      "Number of remaining test labels: 10816\n"
     ]
    }
   ],
   "source": [
    "# Create a list of indices where the sequence length is not 40\n",
    "drop_indices_test = [i for i, seq in enumerate(test_sequences_padded) if len(seq) != 40]\n",
    "\n",
    "# Drop these indices from test_sequences_padded and test_labels\n",
    "test_sequences_padded = [seq for i, seq in enumerate(test_sequences_padded) if i not in drop_indices_test]\n",
    "test_labels = [label for i, label in enumerate(test_labels) if i not in drop_indices_test]\n",
    "\n",
    "# Print the number of remaining sequences and labels\n",
    "print(f\"Number of remaining test sequences: {len(test_sequences_padded)}\")\n",
    "print(f\"Number of remaining test labels: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I previously incorrectly thought this is our batch size for this model run aka window size. (context length),  but batch size needs to rpresent the 43k size we have of segments, not the window size. \n",
    "\n",
    "our final dimensions are 43369 X 40 X 98?? \n",
    "Not sure which dataloader or batch takes which dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch shape: torch.Size([43369, 40, 98])\n"
     ]
    }
   ],
   "source": [
    "train_sequences_tensor = torch.tensor(train_sequences_padded)\n",
    "train_labels = torch.stack(train_labels)\n",
    "# Combine sequences and labels into a single dataset ( train_labels was already a tensor)\n",
    "train_dataset = TensorDataset(train_sequences_tensor, train_labels)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 43369  #  This is because previously we already defined each train_sequences to contain 40 sentences. This is our batch size for this model run aka window size. (context length)\n",
    "\n",
    "#Added drop_last = True so that it would discard an set that had only 39 dimensions. \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# Print the shape of the first batch\n",
    "first_batch = next(iter(train_loader))\n",
    "print('First batch shape:', first_batch[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sequences_tensor shape: torch.Size([43369, 40, 98])\n",
      "train_sequences_tensor dtype: torch.int32\n",
      "train_labels_tensor shape: torch.Size([43369, 40])\n",
      "train_labels_tensor dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "print('train_sequences_tensor shape:', train_sequences_tensor.shape)\n",
    "print('train_sequences_tensor dtype:', train_sequences_tensor.dtype)\n",
    "print('train_labels_tensor shape:', train_labels.shape)\n",
    "print('train_labels_tensor dtype:', train_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tok_embeddings.weight', 'output.weight', 'norm.weight', 'layers.0.attention.query_key_value.weight', 'layers.0.feed_forward.w1.weight', 'layers.0.feed_forward.w3.weight', 'layers.0.attention.wo.weight', 'layers.0.feed_forward.w2.weight', 'layers.0.attention_norm.weight', 'layers.0.ffn_norm.weight', 'layers.1.attention.query_key_value.weight', 'layers.1.feed_forward.w1.weight', 'layers.1.feed_forward.w3.weight', 'layers.1.attention.wo.weight', 'layers.1.feed_forward.w2.weight', 'layers.1.attention_norm.weight', 'layers.1.ffn_norm.weight', 'layers.2.attention.query_key_value.weight', 'layers.2.feed_forward.w1.weight', 'layers.2.feed_forward.w3.weight', 'layers.2.attention.wo.weight', 'layers.2.feed_forward.w2.weight', 'layers.2.attention_norm.weight', 'layers.2.ffn_norm.weight', 'layers.3.attention.query_key_value.weight', 'layers.3.feed_forward.w1.weight', 'layers.3.feed_forward.w3.weight', 'layers.3.attention.wo.weight', 'layers.3.feed_forward.w2.weight', 'layers.3.attention_norm.weight', 'layers.3.ffn_norm.weight', 'layers.4.attention.query_key_value.weight', 'layers.4.feed_forward.w1.weight', 'layers.4.feed_forward.w3.weight', 'layers.4.attention.wo.weight', 'layers.4.feed_forward.w2.weight', 'layers.4.attention_norm.weight', 'layers.4.ffn_norm.weight', 'layers.5.attention.query_key_value.weight', 'layers.5.feed_forward.w1.weight', 'layers.5.feed_forward.w3.weight', 'layers.5.attention.wo.weight', 'layers.5.feed_forward.w2.weight', 'layers.5.attention_norm.weight', 'layers.5.ffn_norm.weight', 'layers.6.attention.query_key_value.weight', 'layers.6.feed_forward.w1.weight', 'layers.6.feed_forward.w3.weight', 'layers.6.attention.wo.weight', 'layers.6.feed_forward.w2.weight', 'layers.6.attention_norm.weight', 'layers.6.ffn_norm.weight', 'layers.7.attention.query_key_value.weight', 'layers.7.feed_forward.w1.weight', 'layers.7.feed_forward.w3.weight', 'layers.7.attention.wo.weight', 'layers.7.feed_forward.w2.weight', 'layers.7.attention_norm.weight', 'layers.7.ffn_norm.weight', 'layers.8.attention.query_key_value.weight', 'layers.8.feed_forward.w1.weight', 'layers.8.feed_forward.w3.weight', 'layers.8.attention.wo.weight', 'layers.8.feed_forward.w2.weight', 'layers.8.attention_norm.weight', 'layers.8.ffn_norm.weight', 'layers.9.attention.query_key_value.weight', 'layers.9.feed_forward.w1.weight', 'layers.9.feed_forward.w3.weight', 'layers.9.attention.wo.weight', 'layers.9.feed_forward.w2.weight', 'layers.9.attention_norm.weight', 'layers.9.ffn_norm.weight', 'layers.10.attention.query_key_value.weight', 'layers.10.feed_forward.w1.weight', 'layers.10.feed_forward.w3.weight', 'layers.10.attention.wo.weight', 'layers.10.feed_forward.w2.weight', 'layers.10.attention_norm.weight', 'layers.10.ffn_norm.weight', 'layers.11.attention.query_key_value.weight', 'layers.11.feed_forward.w1.weight', 'layers.11.feed_forward.w3.weight', 'layers.11.attention.wo.weight', 'layers.11.feed_forward.w2.weight', 'layers.11.attention_norm.weight', 'layers.11.ffn_norm.weight', 'layers.12.attention.query_key_value.weight', 'layers.12.feed_forward.w1.weight', 'layers.12.feed_forward.w3.weight', 'layers.12.attention.wo.weight', 'layers.12.feed_forward.w2.weight', 'layers.12.attention_norm.weight', 'layers.12.ffn_norm.weight', 'layers.13.attention.query_key_value.weight', 'layers.13.feed_forward.w1.weight', 'layers.13.feed_forward.w3.weight', 'layers.13.attention.wo.weight', 'layers.13.feed_forward.w2.weight', 'layers.13.attention_norm.weight', 'layers.13.ffn_norm.weight', 'layers.14.attention.query_key_value.weight', 'layers.14.feed_forward.w1.weight', 'layers.14.feed_forward.w3.weight', 'layers.14.attention.wo.weight', 'layers.14.feed_forward.w2.weight', 'layers.14.attention_norm.weight', 'layers.14.ffn_norm.weight', 'layers.15.attention.query_key_value.weight', 'layers.15.feed_forward.w1.weight', 'layers.15.feed_forward.w3.weight', 'layers.15.attention.wo.weight', 'layers.15.feed_forward.w2.weight', 'layers.15.attention_norm.weight', 'layers.15.ffn_norm.weight', 'layers.16.attention.query_key_value.weight', 'layers.16.feed_forward.w1.weight', 'layers.16.feed_forward.w3.weight', 'layers.16.attention.wo.weight', 'layers.16.feed_forward.w2.weight', 'layers.16.attention_norm.weight', 'layers.16.ffn_norm.weight', 'layers.17.attention.query_key_value.weight', 'layers.17.feed_forward.w1.weight', 'layers.17.feed_forward.w3.weight', 'layers.17.attention.wo.weight', 'layers.17.feed_forward.w2.weight', 'layers.17.attention_norm.weight', 'layers.17.ffn_norm.weight', 'layers.18.attention.query_key_value.weight', 'layers.18.feed_forward.w1.weight', 'layers.18.feed_forward.w3.weight', 'layers.18.attention.wo.weight', 'layers.18.feed_forward.w2.weight', 'layers.18.attention_norm.weight', 'layers.18.ffn_norm.weight', 'layers.19.attention.query_key_value.weight', 'layers.19.feed_forward.w1.weight', 'layers.19.feed_forward.w3.weight', 'layers.19.attention.wo.weight', 'layers.19.feed_forward.w2.weight', 'layers.19.attention_norm.weight', 'layers.19.ffn_norm.weight', 'layers.20.attention.query_key_value.weight', 'layers.20.feed_forward.w1.weight', 'layers.20.feed_forward.w3.weight', 'layers.20.attention.wo.weight', 'layers.20.feed_forward.w2.weight', 'layers.20.attention_norm.weight', 'layers.20.ffn_norm.weight', 'layers.21.attention.query_key_value.weight', 'layers.21.feed_forward.w1.weight', 'layers.21.feed_forward.w3.weight', 'layers.21.attention.wo.weight', 'layers.21.feed_forward.w2.weight', 'layers.21.attention_norm.weight', 'layers.21.ffn_norm.weight', 'layers.22.attention.query_key_value.weight', 'layers.22.feed_forward.w1.weight', 'layers.22.feed_forward.w3.weight', 'layers.22.attention.wo.weight', 'layers.22.feed_forward.w2.weight', 'layers.22.attention_norm.weight', 'layers.22.ffn_norm.weight', 'layers.23.attention.query_key_value.weight', 'layers.23.feed_forward.w1.weight', 'layers.23.feed_forward.w3.weight', 'layers.23.attention.wo.weight', 'layers.23.feed_forward.w2.weight', 'layers.23.attention_norm.weight', 'layers.23.ffn_norm.weight', 'layers.24.attention.query_key_value.weight', 'layers.24.feed_forward.w1.weight', 'layers.24.feed_forward.w3.weight', 'layers.24.attention.wo.weight', 'layers.24.feed_forward.w2.weight', 'layers.24.attention_norm.weight', 'layers.24.ffn_norm.weight', 'layers.25.attention.query_key_value.weight', 'layers.25.feed_forward.w1.weight', 'layers.25.feed_forward.w3.weight', 'layers.25.attention.wo.weight', 'layers.25.feed_forward.w2.weight', 'layers.25.attention_norm.weight', 'layers.25.ffn_norm.weight', 'layers.26.attention.query_key_value.weight', 'layers.26.feed_forward.w1.weight', 'layers.26.feed_forward.w3.weight', 'layers.26.attention.wo.weight', 'layers.26.feed_forward.w2.weight', 'layers.26.attention_norm.weight', 'layers.26.ffn_norm.weight', 'layers.27.attention.query_key_value.weight', 'layers.27.feed_forward.w1.weight', 'layers.27.feed_forward.w3.weight', 'layers.27.attention.wo.weight', 'layers.27.feed_forward.w2.weight', 'layers.27.attention_norm.weight', 'layers.27.ffn_norm.weight', 'layers.28.attention.query_key_value.weight', 'layers.28.feed_forward.w1.weight', 'layers.28.feed_forward.w3.weight', 'layers.28.attention.wo.weight', 'layers.28.feed_forward.w2.weight', 'layers.28.attention_norm.weight', 'layers.28.ffn_norm.weight', 'layers.29.attention.query_key_value.weight', 'layers.29.feed_forward.w1.weight', 'layers.29.feed_forward.w3.weight', 'layers.29.attention.wo.weight', 'layers.29.feed_forward.w2.weight', 'layers.29.attention_norm.weight', 'layers.29.ffn_norm.weight', 'layers.30.attention.query_key_value.weight', 'layers.30.feed_forward.w1.weight', 'layers.30.feed_forward.w3.weight', 'layers.30.attention.wo.weight', 'layers.30.feed_forward.w2.weight', 'layers.30.attention_norm.weight', 'layers.30.ffn_norm.weight', 'layers.31.attention.query_key_value.weight', 'layers.31.feed_forward.w1.weight', 'layers.31.feed_forward.w3.weight', 'layers.31.attention.wo.weight', 'layers.31.feed_forward.w2.weight', 'layers.31.attention_norm.weight', 'layers.31.ffn_norm.weight'])\n",
      "torch.Size([49152, 4096])\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = torch.load('C:\\\\Users\\\\Andrew\\\\Desktop\\\\nasa_project\\\\Juliet\\\\Large Files\\\\aix3-7b-base (1).pt')\n",
    "\n",
    "# Print all keys in the state dictionary\n",
    "print(pretrained_weights.keys())\n",
    "\n",
    "# Once you've identified the key for the embeddings, you can extract them like this:\n",
    "word_vectors = pretrained_weights['tok_embeddings.weight']\n",
    "print(word_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(691)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pretrained_weights):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embedding.weight.data.copy_(pretrained_weights)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        # Concatenate the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        # and apply dropout\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        return self.fc(hidden)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running into memory issues with this vocab size. Going to try to reduce vocabulary by trimming embedding dimensions to 20k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 4096])\n"
     ]
    }
   ],
   "source": [
    "trimmed_word_vectors = word_vectors[:20000, :]\n",
    "print(trimmed_word_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (20000) must match the size of tensor b (49152) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m691\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLSTMClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEMBEDDING_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLSTM_NODES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Changed from 2 to 40 to match your label dimensions\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mword_vectors\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[38], line 11\u001b[0m, in \u001b[0;36mLSTMClassifier.__init__\u001b[1;34m(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pretrained_weights)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(hidden_dim \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, output_dim)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(dropout)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (20000) must match the size of tensor b (49152) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(691)\n",
    "\n",
    "# Initialize the model\n",
    "model = LSTMClassifier(\n",
    "    vocab_size=20000,\n",
    "    embedding_dim=EMBEDDING_SIZE,  \n",
    "    hidden_dim=LSTM_NODES,\n",
    "    output_dim=40,  # Changed from 2 to 40 to match your label dimensions\n",
    "    n_layers=2,\n",
    "    bidirectional=True,\n",
    "    dropout=0.5,\n",
    "    pretrained_weights=trimmed_word_vectors\n",
    ")\n",
    "print(model)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculations\n",
    "with torch.no_grad():\n",
    "    # Get the first batch of data from the training loader\n",
    "    batch_sequences, batch_labels = next(iter(train_loader))\n",
    "\n",
    "    # Pass the batch of sequences through the model\n",
    "    outputs = model(batch_sequences)\n",
    "\n",
    "    # Print the shape of the outputs\n",
    "    print(outputs.shape)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for batch_sequences, batch_labels in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_sequences)\n",
    "        # Ensure the predictions and labels have the same shape\n",
    "        predictions = predictions.view(batch_labels.shape[0], -1)\n",
    "        loss = criterion(predictions, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_sequences, batch_labels in iterator:\n",
    "            predictions = model(batch_sequences)\n",
    "            loss = criterion(predictions, batch_labels)\n",
    "            epoch_loss += loss.item()\n",
    "            # Apply softmax to the model's output\n",
    "            probabilities = F.softmax(predictions, dim=1)\n",
    "            # Keep only the probability of the positive class\n",
    "            positive_probabilities = probabilities[:, 1]\n",
    "            all_predictions.extend(positive_probabilities.detach().numpy())\n",
    "            all_labels.extend(batch_labels.detach().numpy())\n",
    "    return epoch_loss / len(iterator), all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The output shape [64, 2] is what we expect for a sequence classification task. This means that for each sequence in the batch (64 in total), the model is outputting a 2-dimensional vector. These vectors can be interpreted as the probabilities of each sequence belonging to each of the two classes (good or bad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[64, -1]' is invalid for input of size 1304",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m valid_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPOCHS):\n\u001b[1;32m---> 12\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, criterion)\n\u001b[0;32m     14\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[82], line 39\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[0;32m     37\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model(batch_sequences)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Ensure the predictions and labels have the same shape\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(predictions, batch_labels)\n\u001b[0;32m     41\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[64, -1]' is invalid for input of size 1304"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the number of epochs\n",
    "N_EPOCHS = 10\n",
    "\n",
    "# Store the loss values for plotting\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    valid_loss = evaluate(model, test_loader, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.3f}, Val. Loss: {valid_loss:.3f}')\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "train_loss, _, _ = train(model, train_loader, optimizer, criterion)\n",
    "valid_loss, predictions, labels = evaluate(model, test_loader, criterion)\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, _ = roc_curve(labels, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "unique_labels = torch.unique(batch_labels)\n",
    "print(unique_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
