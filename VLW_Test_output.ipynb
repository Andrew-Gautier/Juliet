{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071178fb",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [14]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68003ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:25:12.471121Z",
     "iopub.status.busy": "2024-06-17T00:25:12.470941Z",
     "iopub.status.idle": "2024-06-17T00:26:35.775050Z",
     "shell.execute_reply": "2024-06-17T00:26:35.774570Z"
    },
    "papermill": {
     "duration": 83.310399,
     "end_time": "2024-06-17T00:26:35.776461",
     "exception": false,
     "start_time": "2024-06-17T00:25:12.466062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 20:25:26.326528: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import the required libraries:\n",
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "from keras.utils import pad_sequences\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from config import create_session, Cases, VLW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22630864",
   "metadata": {
    "papermill": {
     "duration": 0.002895,
     "end_time": "2024-06-17T00:26:35.784959",
     "exception": false,
     "start_time": "2024-06-17T00:26:35.782064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Intializing the new tokenizer + model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a2d41b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:26:35.791518Z",
     "iopub.status.busy": "2024-06-17T00:26:35.791165Z",
     "iopub.status.idle": "2024-06-17T00:26:35.794274Z",
     "shell.execute_reply": "2024-06-17T00:26:35.793883Z"
    },
    "papermill": {
     "duration": 0.007675,
     "end_time": "2024-06-17T00:26:35.795337",
     "exception": false,
     "start_time": "2024-06-17T00:26:35.787662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Execute this script to set values for different parameters:\n",
    "BATCH_SIZE = 10\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_SENTENCES =40\n",
    "EPOCHS = 20\n",
    "LSTM_NODES = 256\n",
    "\n",
    "MAX_SENTENCE_LENGTH = 98\n",
    "VOCAB_SIZE = 10000\n",
    "# 4096 is the dimension returned from the tok_embeddings.weight key of the pretrained aix model\n",
    "EMBEDDING_SIZE = 4096\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ca1f6",
   "metadata": {
    "papermill": {
     "duration": 0.002607,
     "end_time": "2024-06-17T00:26:35.801864",
     "exception": false,
     "start_time": "2024-06-17T00:26:35.799257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preparation for Thorny Flat Cluster Access\n",
    "\n",
    "1. Pytorch model loading/saving.\n",
    "2. Jupyter commands for distributing work across multiple clusters. \n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e64f884",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:26:35.807861Z",
     "iopub.status.busy": "2024-06-17T00:26:35.807656Z",
     "iopub.status.idle": "2024-06-17T00:26:35.925796Z",
     "shell.execute_reply": "2024-06-17T00:26:35.925385Z"
    },
    "papermill": {
     "duration": 0.122264,
     "end_time": "2024-06-17T00:26:35.926847",
     "exception": false,
     "start_time": "2024-06-17T00:26:35.804583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('tokenizer.model')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA Available:\", cuda_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a530c",
   "metadata": {
    "papermill": {
     "duration": 0.002787,
     "end_time": "2024-06-17T00:26:35.932493",
     "exception": false,
     "start_time": "2024-06-17T00:26:35.929706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Get the target sequences ready to be passed into the model features will be the tokenized sequences, labels will be the binary classification of which set of tokens represents the bad sequence. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba95939d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:26:35.938777Z",
     "iopub.status.busy": "2024-06-17T00:26:35.938561Z",
     "iopub.status.idle": "2024-06-17T00:27:04.108698Z",
     "shell.execute_reply": "2024-06-17T00:27:04.108247Z"
    },
    "papermill": {
     "duration": 28.174612,
     "end_time": "2024-06-17T00:27:04.109837",
     "exception": false,
     "start_time": "2024-06-17T00:26:35.935225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length: 98\n",
      "Train Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
      "Test Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "session = create_session()\n",
    "\n",
    "# Query the database and get a list of Cases objects for each CWE\n",
    "records = session.query(VLW).all()\n",
    "\n",
    "data = [record.vlw_content for record in records]\n",
    "labels  = [record.vulnerability_location  for record in records]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "# Encode sentences \n",
    "train_sequences = [[sp.EncodeAsIds(line) for line in text.split('\\n')[:40]] for text in train_data]\n",
    "test_sequences = [[sp.EncodeAsIds(line) for line in text.split('\\n')[:40]] for text in test_data]\n",
    "\n",
    "\n",
    "# This version could be useful if I want to avoid the padding issue later on. \n",
    "# train_sequences = [[sp.EncodeAsIds(line) for line in text.split('\\n')[:40]] for text in train_data if len(text.split('\\n')) >= 40]\n",
    "# test_sequences = [[sp.EncodeAsIds(line) for line in text.split('\\n')[:40]] for text in test_data if len(text.split('\\n')) >= 40]\n",
    "\n",
    "# # Print the number of train and test sequences\n",
    "# print(f\"Number of train sequences: {len(train_sequences)}\")\n",
    "# print(f\"Number of test sequences: {len(test_sequences)}\")\n",
    "\n",
    "\n",
    "# Finding the longest indivudial tokenized sentences\n",
    "max_length_train = max(max(len(seq) for seq in text) for text in train_sequences)\n",
    "max_length_test = max(max(len(seq) for seq in text) for text in test_sequences)\n",
    "\n",
    "# Get the maximum length across both sets\n",
    "max_length = max(max_length_train, max_length_test)\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "\n",
    "num_classes = 40  \n",
    "train_labels = torch.stack([torch.nn.functional.one_hot(torch.tensor(label), num_classes=num_classes) for label in train_labels])\n",
    "test_labels = torch.stack([torch.nn.functional.one_hot(torch.tensor(label), num_classes=num_classes) for label in test_labels])\n",
    "\n",
    "print('max_length:', max_length)\n",
    "print('Train Labels:', train_labels[0])\n",
    "print('Test Labels:', test_labels[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8837eee3",
   "metadata": {
    "papermill": {
     "duration": 0.002784,
     "end_time": "2024-06-17T00:27:04.116632",
     "exception": false,
     "start_time": "2024-06-17T00:27:04.113848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Padding + Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b0a9e64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:27:04.123014Z",
     "iopub.status.busy": "2024-06-17T00:27:04.122777Z",
     "iopub.status.idle": "2024-06-17T00:27:08.196329Z",
     "shell.execute_reply": "2024-06-17T00:27:08.195847Z"
    },
    "papermill": {
     "duration": 4.078026,
     "end_time": "2024-06-17T00:27:08.197401",
     "exception": false,
     "start_time": "2024-06-17T00:27:04.119375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequences shape: (40, 98)\n",
      "Test sequences shape: (40, 98)\n"
     ]
    }
   ],
   "source": [
    "# Pad each individual sequence to a length of 98\n",
    "train_sequences_padded = [pad_sequences(text, maxlen=98, padding='post') for text in train_sequences]\n",
    "test_sequences_padded = [pad_sequences(text, maxlen=98, padding='post') for text in test_sequences]\n",
    "\n",
    "print('Train sequences shape:', train_sequences_padded[0].shape)\n",
    "print('Test sequences shape:', test_sequences_padded[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef24b3",
   "metadata": {
    "papermill": {
     "duration": 0.002998,
     "end_time": "2024-06-17T00:27:08.204810",
     "exception": false,
     "start_time": "2024-06-17T00:27:08.201812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Debugging the shape here there is a 39 dimension tensor throwing things off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8839e793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:27:08.211653Z",
     "iopub.status.busy": "2024-06-17T00:27:08.211421Z",
     "iopub.status.idle": "2024-06-17T00:27:09.824314Z",
     "shell.execute_reply": "2024-06-17T00:27:09.823890Z"
    },
    "papermill": {
     "duration": 1.617657,
     "end_time": "2024-06-17T00:27:09.825397",
     "exception": false,
     "start_time": "2024-06-17T00:27:08.207740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining train sequences: 43369\n",
      "Number of remaining train labels: 43369\n"
     ]
    }
   ],
   "source": [
    "# Create a list of indices where the sequence length is not 40\n",
    "drop_indices = [i for i, seq in enumerate(train_sequences_padded) if len(seq) != 40]\n",
    "\n",
    "# Drop these indices from train_sequences_padded and train_labels\n",
    "train_sequences_padded = [seq for i, seq in enumerate(train_sequences_padded) if i not in drop_indices]\n",
    "train_labels = [label for i, label in enumerate(train_labels) if i not in drop_indices]\n",
    "\n",
    "# Print the number of remaining sequences and labels\n",
    "print(f\"Number of remaining train sequences: {len(train_sequences_padded)}\")\n",
    "print(f\"Number of remaining train labels: {len(train_labels)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef974a0",
   "metadata": {
    "papermill": {
     "duration": 0.003084,
     "end_time": "2024-06-17T00:27:09.831615",
     "exception": false,
     "start_time": "2024-06-17T00:27:09.828531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Just going to cull the few thousand or so that had an inoccrect length, still testing about 40k windows it looks like. Reapeating the same for testing group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8dda7d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:27:09.838161Z",
     "iopub.status.busy": "2024-06-17T00:27:09.837940Z",
     "iopub.status.idle": "2024-06-17T00:27:09.963442Z",
     "shell.execute_reply": "2024-06-17T00:27:09.963039Z"
    },
    "papermill": {
     "duration": 0.129953,
     "end_time": "2024-06-17T00:27:09.964517",
     "exception": false,
     "start_time": "2024-06-17T00:27:09.834564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining test sequences: 10816\n",
      "Number of remaining test labels: 10816\n"
     ]
    }
   ],
   "source": [
    "# Create a list of indices where the sequence length is not 40\n",
    "drop_indices_test = [i for i, seq in enumerate(test_sequences_padded) if len(seq) != 40]\n",
    "\n",
    "# Drop these indices from test_sequences_padded and test_labels\n",
    "test_sequences_padded = [seq for i, seq in enumerate(test_sequences_padded) if i not in drop_indices_test]\n",
    "test_labels = [label for i, label in enumerate(test_labels) if i not in drop_indices_test]\n",
    "\n",
    "# Print the number of remaining sequences and labels\n",
    "print(f\"Number of remaining test sequences: {len(test_sequences_padded)}\")\n",
    "print(f\"Number of remaining test labels: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7967c6f5",
   "metadata": {
    "papermill": {
     "duration": 0.002738,
     "end_time": "2024-06-17T00:27:09.970390",
     "exception": false,
     "start_time": "2024-06-17T00:27:09.967652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I previously incorrectly thought this is our batch size for this model run aka window size. (context length),  but batch size needs to rpresent the 43k size we have of segments, not the window size. \n",
    "\n",
    "our final dimensions are 43369 X 40 X 98?? \n",
    "Not sure which dataloader or batch takes which dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c852fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:27:09.976967Z",
     "iopub.status.busy": "2024-06-17T00:27:09.976751Z",
     "iopub.status.idle": "2024-06-17T00:27:28.665118Z",
     "shell.execute_reply": "2024-06-17T00:27:28.664640Z"
    },
    "papermill": {
     "duration": 18.693187,
     "end_time": "2024-06-17T00:27:28.666448",
     "exception": false,
     "start_time": "2024-06-17T00:27:09.973261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First train batch shape: torch.Size([10, 40, 98])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32972/3929828629.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400268359/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  train_sequences_tensor = torch.tensor(train_sequences_padded)\n"
     ]
    }
   ],
   "source": [
    "train_sequences_tensor = torch.tensor(train_sequences_padded)\n",
    "# Assuming train_labels needs to be stacked for a specific reason\n",
    "train_labels = torch.stack(train_labels)  # Keep this if it's necessary for your model\n",
    "train_dataset = TensorDataset(train_sequences_tensor, train_labels)\n",
    "\n",
    "# Create a DataLoader with a specific batch size and drop_last option\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# Print the shape of the first batch\n",
    "first_batch = next(iter(train_loader))\n",
    "print('First train batch shape:', first_batch[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c79a6",
   "metadata": {
    "papermill": {
     "duration": 0.003776,
     "end_time": "2024-06-17T00:27:28.675281",
     "exception": false,
     "start_time": "2024-06-17T00:27:28.671505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next creating the data loader for the test labels too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e5756af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:27:28.683432Z",
     "iopub.status.busy": "2024-06-17T00:27:28.683202Z",
     "iopub.status.idle": "2024-06-17T00:27:33.411728Z",
     "shell.execute_reply": "2024-06-17T00:27:33.411284Z"
    },
    "papermill": {
     "duration": 4.733971,
     "end_time": "2024-06-17T00:27:33.412815",
     "exception": false,
     "start_time": "2024-06-17T00:27:28.678844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First test batch shape: torch.Size([10, 40, 98])\n"
     ]
    }
   ],
   "source": [
    "test_sequences_tensor = torch.tensor(test_sequences_padded)\n",
    "test_labels = torch.stack(test_labels)\n",
    "test_dataset = TensorDataset(test_sequences_tensor, test_labels)\n",
    "batch_size = 10\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "first_batch = next(iter(test_loader))\n",
    "print('First test batch shape:', first_batch[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34a0056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:27:33.420962Z",
     "iopub.status.busy": "2024-06-17T00:27:33.420745Z",
     "iopub.status.idle": "2024-06-17T00:27:33.495598Z",
     "shell.execute_reply": "2024-06-17T00:27:33.495204Z"
    },
    "papermill": {
     "duration": 0.079659,
     "end_time": "2024-06-17T00:27:33.496631",
     "exception": false,
     "start_time": "2024-06-17T00:27:33.416972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sequences_tensor shape: torch.Size([43369, 40, 98])\n",
      "train_sequences_tensor dtype: torch.int32\n",
      "train_labels_tensor shape: torch.Size([43369, 40])\n",
      "train_labels_tensor dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "print('train_sequences_tensor shape:', train_sequences_tensor.shape)\n",
    "print('train_sequences_tensor dtype:', train_sequences_tensor.dtype)\n",
    "print('train_labels_tensor shape:', train_labels.shape)\n",
    "print('train_labels_tensor dtype:', train_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb5b8fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:27:33.503900Z",
     "iopub.status.busy": "2024-06-17T00:27:33.503709Z",
     "iopub.status.idle": "2024-06-17T00:27:42.829701Z",
     "shell.execute_reply": "2024-06-17T00:27:42.829138Z"
    },
    "papermill": {
     "duration": 9.330853,
     "end_time": "2024-06-17T00:27:42.830732",
     "exception": false,
     "start_time": "2024-06-17T00:27:33.499879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded successfully.\n",
      "dict_keys(['tok_embeddings.weight', 'output.weight', 'norm.weight', 'layers.0.attention.query_key_value.weight', 'layers.0.feed_forward.w1.weight', 'layers.0.feed_forward.w3.weight', 'layers.0.attention.wo.weight', 'layers.0.feed_forward.w2.weight', 'layers.0.attention_norm.weight', 'layers.0.ffn_norm.weight', 'layers.1.attention.query_key_value.weight', 'layers.1.feed_forward.w1.weight', 'layers.1.feed_forward.w3.weight', 'layers.1.attention.wo.weight', 'layers.1.feed_forward.w2.weight', 'layers.1.attention_norm.weight', 'layers.1.ffn_norm.weight', 'layers.2.attention.query_key_value.weight', 'layers.2.feed_forward.w1.weight', 'layers.2.feed_forward.w3.weight', 'layers.2.attention.wo.weight', 'layers.2.feed_forward.w2.weight', 'layers.2.attention_norm.weight', 'layers.2.ffn_norm.weight', 'layers.3.attention.query_key_value.weight', 'layers.3.feed_forward.w1.weight', 'layers.3.feed_forward.w3.weight', 'layers.3.attention.wo.weight', 'layers.3.feed_forward.w2.weight', 'layers.3.attention_norm.weight', 'layers.3.ffn_norm.weight', 'layers.4.attention.query_key_value.weight', 'layers.4.feed_forward.w1.weight', 'layers.4.feed_forward.w3.weight', 'layers.4.attention.wo.weight', 'layers.4.feed_forward.w2.weight', 'layers.4.attention_norm.weight', 'layers.4.ffn_norm.weight', 'layers.5.attention.query_key_value.weight', 'layers.5.feed_forward.w1.weight', 'layers.5.feed_forward.w3.weight', 'layers.5.attention.wo.weight', 'layers.5.feed_forward.w2.weight', 'layers.5.attention_norm.weight', 'layers.5.ffn_norm.weight', 'layers.6.attention.query_key_value.weight', 'layers.6.feed_forward.w1.weight', 'layers.6.feed_forward.w3.weight', 'layers.6.attention.wo.weight', 'layers.6.feed_forward.w2.weight', 'layers.6.attention_norm.weight', 'layers.6.ffn_norm.weight', 'layers.7.attention.query_key_value.weight', 'layers.7.feed_forward.w1.weight', 'layers.7.feed_forward.w3.weight', 'layers.7.attention.wo.weight', 'layers.7.feed_forward.w2.weight', 'layers.7.attention_norm.weight', 'layers.7.ffn_norm.weight', 'layers.8.attention.query_key_value.weight', 'layers.8.feed_forward.w1.weight', 'layers.8.feed_forward.w3.weight', 'layers.8.attention.wo.weight', 'layers.8.feed_forward.w2.weight', 'layers.8.attention_norm.weight', 'layers.8.ffn_norm.weight', 'layers.9.attention.query_key_value.weight', 'layers.9.feed_forward.w1.weight', 'layers.9.feed_forward.w3.weight', 'layers.9.attention.wo.weight', 'layers.9.feed_forward.w2.weight', 'layers.9.attention_norm.weight', 'layers.9.ffn_norm.weight', 'layers.10.attention.query_key_value.weight', 'layers.10.feed_forward.w1.weight', 'layers.10.feed_forward.w3.weight', 'layers.10.attention.wo.weight', 'layers.10.feed_forward.w2.weight', 'layers.10.attention_norm.weight', 'layers.10.ffn_norm.weight', 'layers.11.attention.query_key_value.weight', 'layers.11.feed_forward.w1.weight', 'layers.11.feed_forward.w3.weight', 'layers.11.attention.wo.weight', 'layers.11.feed_forward.w2.weight', 'layers.11.attention_norm.weight', 'layers.11.ffn_norm.weight', 'layers.12.attention.query_key_value.weight', 'layers.12.feed_forward.w1.weight', 'layers.12.feed_forward.w3.weight', 'layers.12.attention.wo.weight', 'layers.12.feed_forward.w2.weight', 'layers.12.attention_norm.weight', 'layers.12.ffn_norm.weight', 'layers.13.attention.query_key_value.weight', 'layers.13.feed_forward.w1.weight', 'layers.13.feed_forward.w3.weight', 'layers.13.attention.wo.weight', 'layers.13.feed_forward.w2.weight', 'layers.13.attention_norm.weight', 'layers.13.ffn_norm.weight', 'layers.14.attention.query_key_value.weight', 'layers.14.feed_forward.w1.weight', 'layers.14.feed_forward.w3.weight', 'layers.14.attention.wo.weight', 'layers.14.feed_forward.w2.weight', 'layers.14.attention_norm.weight', 'layers.14.ffn_norm.weight', 'layers.15.attention.query_key_value.weight', 'layers.15.feed_forward.w1.weight', 'layers.15.feed_forward.w3.weight', 'layers.15.attention.wo.weight', 'layers.15.feed_forward.w2.weight', 'layers.15.attention_norm.weight', 'layers.15.ffn_norm.weight', 'layers.16.attention.query_key_value.weight', 'layers.16.feed_forward.w1.weight', 'layers.16.feed_forward.w3.weight', 'layers.16.attention.wo.weight', 'layers.16.feed_forward.w2.weight', 'layers.16.attention_norm.weight', 'layers.16.ffn_norm.weight', 'layers.17.attention.query_key_value.weight', 'layers.17.feed_forward.w1.weight', 'layers.17.feed_forward.w3.weight', 'layers.17.attention.wo.weight', 'layers.17.feed_forward.w2.weight', 'layers.17.attention_norm.weight', 'layers.17.ffn_norm.weight', 'layers.18.attention.query_key_value.weight', 'layers.18.feed_forward.w1.weight', 'layers.18.feed_forward.w3.weight', 'layers.18.attention.wo.weight', 'layers.18.feed_forward.w2.weight', 'layers.18.attention_norm.weight', 'layers.18.ffn_norm.weight', 'layers.19.attention.query_key_value.weight', 'layers.19.feed_forward.w1.weight', 'layers.19.feed_forward.w3.weight', 'layers.19.attention.wo.weight', 'layers.19.feed_forward.w2.weight', 'layers.19.attention_norm.weight', 'layers.19.ffn_norm.weight', 'layers.20.attention.query_key_value.weight', 'layers.20.feed_forward.w1.weight', 'layers.20.feed_forward.w3.weight', 'layers.20.attention.wo.weight', 'layers.20.feed_forward.w2.weight', 'layers.20.attention_norm.weight', 'layers.20.ffn_norm.weight', 'layers.21.attention.query_key_value.weight', 'layers.21.feed_forward.w1.weight', 'layers.21.feed_forward.w3.weight', 'layers.21.attention.wo.weight', 'layers.21.feed_forward.w2.weight', 'layers.21.attention_norm.weight', 'layers.21.ffn_norm.weight', 'layers.22.attention.query_key_value.weight', 'layers.22.feed_forward.w1.weight', 'layers.22.feed_forward.w3.weight', 'layers.22.attention.wo.weight', 'layers.22.feed_forward.w2.weight', 'layers.22.attention_norm.weight', 'layers.22.ffn_norm.weight', 'layers.23.attention.query_key_value.weight', 'layers.23.feed_forward.w1.weight', 'layers.23.feed_forward.w3.weight', 'layers.23.attention.wo.weight', 'layers.23.feed_forward.w2.weight', 'layers.23.attention_norm.weight', 'layers.23.ffn_norm.weight', 'layers.24.attention.query_key_value.weight', 'layers.24.feed_forward.w1.weight', 'layers.24.feed_forward.w3.weight', 'layers.24.attention.wo.weight', 'layers.24.feed_forward.w2.weight', 'layers.24.attention_norm.weight', 'layers.24.ffn_norm.weight', 'layers.25.attention.query_key_value.weight', 'layers.25.feed_forward.w1.weight', 'layers.25.feed_forward.w3.weight', 'layers.25.attention.wo.weight', 'layers.25.feed_forward.w2.weight', 'layers.25.attention_norm.weight', 'layers.25.ffn_norm.weight', 'layers.26.attention.query_key_value.weight', 'layers.26.feed_forward.w1.weight', 'layers.26.feed_forward.w3.weight', 'layers.26.attention.wo.weight', 'layers.26.feed_forward.w2.weight', 'layers.26.attention_norm.weight', 'layers.26.ffn_norm.weight', 'layers.27.attention.query_key_value.weight', 'layers.27.feed_forward.w1.weight', 'layers.27.feed_forward.w3.weight', 'layers.27.attention.wo.weight', 'layers.27.feed_forward.w2.weight', 'layers.27.attention_norm.weight', 'layers.27.ffn_norm.weight', 'layers.28.attention.query_key_value.weight', 'layers.28.feed_forward.w1.weight', 'layers.28.feed_forward.w3.weight', 'layers.28.attention.wo.weight', 'layers.28.feed_forward.w2.weight', 'layers.28.attention_norm.weight', 'layers.28.ffn_norm.weight', 'layers.29.attention.query_key_value.weight', 'layers.29.feed_forward.w1.weight', 'layers.29.feed_forward.w3.weight', 'layers.29.attention.wo.weight', 'layers.29.feed_forward.w2.weight', 'layers.29.attention_norm.weight', 'layers.29.ffn_norm.weight', 'layers.30.attention.query_key_value.weight', 'layers.30.feed_forward.w1.weight', 'layers.30.feed_forward.w3.weight', 'layers.30.attention.wo.weight', 'layers.30.feed_forward.w2.weight', 'layers.30.attention_norm.weight', 'layers.30.ffn_norm.weight', 'layers.31.attention.query_key_value.weight', 'layers.31.feed_forward.w1.weight', 'layers.31.feed_forward.w3.weight', 'layers.31.attention.wo.weight', 'layers.31.feed_forward.w2.weight', 'layers.31.attention_norm.weight', 'layers.31.ffn_norm.weight'])\n",
      "torch.Size([49152, 4096])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pretrained_weights = torch.load('aix3-7b-base-1.pt')\n",
    "    print(\"Weights loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load weights: {e}\")\n",
    "\n",
    "# Print all keys in the state dictionary\n",
    "print(pretrained_weights.keys())\n",
    "\n",
    "# Once you've identified the key for the embeddings, you can extract them like this:\n",
    "word_vectors = pretrained_weights['tok_embeddings.weight']\n",
    "print(word_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8754a65f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:27:42.839723Z",
     "iopub.status.busy": "2024-06-17T00:27:42.839494Z",
     "iopub.status.idle": "2024-06-17T00:27:42.884657Z",
     "shell.execute_reply": "2024-06-17T00:27:42.884288Z"
    },
    "papermill": {
     "duration": 0.050373,
     "end_time": "2024-06-17T00:27:42.885728",
     "exception": false,
     "start_time": "2024-06-17T00:27:42.835355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(691)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pretrained_weights):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embedding.weight.data.copy_(pretrained_weights)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # BATCH_SIZE, NUM_SENTENCES, MAX_SENTENCE_LENGTH = text.size()\n",
    "        # text = text.view(BATCH_SIZE * NUM_SENTENCES, MAX_SENTENCE_LENGTH)\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        print(f\"Shape after embedding: {embedded.shape}\")\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        print(f\"Shape after LSTM: {output.shape}\")\n",
    "        \n",
    "        # hidden = hidden.view(BATCH_SIZE, NUM_SENTENCES, -1)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        print(f\"Shape of hidden: {hidden.shape}\")\n",
    "        return self.fc(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d60a9ccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:27:42.892967Z",
     "iopub.status.busy": "2024-06-17T00:27:42.892772Z",
     "iopub.status.idle": "2024-06-17T00:27:44.233295Z",
     "shell.execute_reply": "2024-06-17T00:27:44.232802Z"
    },
    "papermill": {
     "duration": 1.345646,
     "end_time": "2024-06-17T00:27:44.234549",
     "exception": false,
     "start_time": "2024-06-17T00:27:42.888903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = 49152  # Vocabulary size\n",
    "embedding_dim = 4096  # Embedding dimension\n",
    "hidden_dim = 256  # Hidden dimension of LSTM\n",
    "output_dim = 40  # Output dimension\n",
    "n_layers = 2  # Number of LSTM layers\n",
    "bidirectional = True  # Whether the LSTM is bidirectional\n",
    "dropout = 0.5  # Dropout rate\n",
    "pretrained_weights = word_vectors  # Pretrained weights\n",
    "\n",
    "model = LSTMClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, word_vectors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b9a6d0",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f8d2a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T00:27:44.243654Z",
     "iopub.status.busy": "2024-06-17T00:27:44.243425Z",
     "iopub.status.idle": "2024-06-17T00:27:46.373242Z",
     "shell.execute_reply": "2024-06-17T00:27:46.372535Z"
    },
    "papermill": {
     "duration": 2.135437,
     "end_time": "2024-06-17T00:27:46.374163",
     "exception": true,
     "start_time": "2024-06-17T00:27:44.238726",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (embedding): Embedding(49152, 4096)\n",
      "  (rnn): LSTM(4096, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
      "  (fc): Linear(in_features=512, out_features=40, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Shape after embedding: torch.Size([10, 40, 98, 4096])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "LSTM: Expected input to be 2D or 3D, got 4D instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     batch_sequences \u001b[38;5;241m=\u001b[39m batch_sequences\u001b[38;5;241m.\u001b[39mview(batch_size \u001b[38;5;241m*\u001b[39m num_sentences, seq_len)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Pass the batch of sequences through the model\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch_sequences)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Print the shape of the outputs\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.conda/envs/python3112/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/python3112/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m, in \u001b[0;36mLSTMClassifier.forward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     16\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(text))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape after embedding: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedded\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m output, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(embedded)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape after LSTM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# hidden = hidden.view(BATCH_SIZE, NUM_SENTENCES, -1)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/python3112/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/python3112/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/python3112/lib/python3.11/site-packages/torch/nn/modules/rnn.py:845\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m--> 845\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM: Expected input to be 2D or 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    846\u001b[0m     is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    847\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: LSTM: Expected input to be 2D or 3D, got 4D instead"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(691)\n",
    "\n",
    "# Initialize the model\n",
    "model = LSTMClassifier(\n",
    "    vocab_size=49152,\n",
    "    embedding_dim=EMBEDDING_SIZE,  \n",
    "    hidden_dim=LSTM_NODES,\n",
    "    output_dim=40,  # Changed from 2 to 40 to match your label dimensions\n",
    "    n_layers=2,\n",
    "    bidirectional=True,\n",
    "    dropout=0.5,\n",
    "    pretrained_weights=word_vectors\n",
    ")\n",
    "print(model)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculations\n",
    "with torch.no_grad():\n",
    "    # Get the first batch of data from the training loader\n",
    "    batch_sequences, batch_labels = next(iter(train_loader))\n",
    "\n",
    "    if batch_sequences.dim() == 4:\n",
    "        batch_size, num_sentences, seq_len, _ = batch_sequences.size()\n",
    "        batch_sequences = batch_sequences.view(batch_size * num_sentences, seq_len)\n",
    "        \n",
    "    # Pass the batch of sequences through the model\n",
    "    outputs = model(batch_sequences)\n",
    "\n",
    "    # Print the shape of the outputs\n",
    "    print(outputs.shape)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    four_d_tensors_count = 0  # Counter for 4D tensors\n",
    "    for batch_sequences, batch_labels in iterator:\n",
    "        # Check if batch_sequences is a 4D tensor\n",
    "        if batch_sequences.dim() == 4:\n",
    "            batch_size, num_sentences, seq_len, _ = batch_sequences.size()\n",
    "            batch_sequences = batch_sequences.view(batch_size * num_sentences, seq_len)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_sequences)\n",
    "        predictions = predictions.view(batch_labels.shape[0], -1)\n",
    "        loss = criterion(predictions, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    if four_d_tensors_count > 0:\n",
    "        print(f\"Skipped {four_d_tensors_count} batches due to 4D tensor inputs.\")\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    four_d_tensors_count = 0  # Counter for 4D tensors\n",
    "    with torch.no_grad():\n",
    "        for batch_sequences, batch_labels in iterator:\n",
    "            # Check if batch_sequences is a 4D tensor\n",
    "            if batch_sequences.dim() == 4:\n",
    "                batch_size, num_sentences, seq_len, _ = batch_sequences.size()\n",
    "                batch_sequences = batch_sequences.view(batch_size * num_sentences, seq_len)\n",
    "            \n",
    "            predictions = model(batch_sequences)\n",
    "            loss = criterion(predictions, batch_labels)\n",
    "            epoch_loss += loss.item()\n",
    "            probabilities = F.softmax(predictions, dim=1)\n",
    "            positive_probabilities = probabilities[:, 1]\n",
    "            all_predictions.extend(positive_probabilities.cpu().detach().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().detach().numpy())\n",
    "    \n",
    "    \n",
    "    return epoch_loss / len(iterator), all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f5551",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    " The output shape [64, 2] is what we expect for a sequence classification task. This means that for each sequence in the batch (64 in total), the model is outputting a 2-dimensional vector. These vectors can be interpreted as the probabilities of each sequence belonging to each of the two classes (good or bad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed57b2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the number of epochs\n",
    "N_EPOCHS = 10\n",
    "\n",
    "# Store the loss values for plotting\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss, predictions, labels = evaluate(model, test_loader, criterion, device)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.3f}, Val. Loss: {valid_loss:.3f}')\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "train_loss, _, _ = train(model, train_loader, optimizer, criterion)\n",
    "valid_loss, predictions, labels = evaluate(model, test_loader, criterion)\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, _ = roc_curve(labels, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868d898",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_labels = torch.unique(batch_labels)\n",
    "print(unique_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 167.356259,
   "end_time": "2024-06-17T00:27:49.994733",
   "environment_variables": {},
   "exception": true,
   "input_path": "VLW_Test.ipynb",
   "output_path": "VLW_Test_output.ipynb",
   "parameters": {},
   "start_time": "2024-06-17T00:25:02.638474",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}